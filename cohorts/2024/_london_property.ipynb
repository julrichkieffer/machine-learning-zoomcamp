{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London House Price Data\n",
    "100,000 sold house prices from 1995 to Oct 2024\n",
    "\n",
    "https://www.kaggle.com/datasets/jakewright/house-price-data\n",
    "https://www.kaggle.com/code/jakewright/predicting-house-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_properties = pd.read_parquet('/kaggle/input/house-price-data/kaggle_london_house_price_data.parquet').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_properties['history_date'] = pd.to_datetime(all_properties['history_date'])\n",
    "\n",
    "all_properties['week'] = all_properties['history_date'].dt.isocalendar().week\n",
    "all_properties['dayofyear'] = all_properties['history_date'].dt.day_of_year\n",
    "all_properties['dayofmonth'] = all_properties['history_date'].dt.day\n",
    "\n",
    "all_properties['month'] = all_properties['history_date'].dt.month\n",
    "all_properties['year'] = all_properties['history_date'].dt.year\n",
    "all_properties['quarter'] = all_properties['history_date'].dt.quarter\n",
    "\n",
    "all_properties['bed-bath'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['bathrooms'].astype(str)\n",
    "all_properties['bed-liv'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['livingRooms'].astype(str)\n",
    "all_properties['bed-bath-liv'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['bathrooms'].astype(str) +'-'+ all_properties['livingRooms'].astype(str)\n",
    "\n",
    "all_properties['Area_Binned_Low_500'] = pd.cut(all_properties['floorAreaSqM'], bins=500).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "all_properties['Area_Binned_Low_250'] = pd.cut(all_properties['floorAreaSqM'], bins=250).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "all_properties['Area_Binned_Low_10'] = pd.cut(all_properties['floorAreaSqM'], bins=10).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "\n",
    "all_properties['quadrant'] = all_properties['postcode'].str[:1]\n",
    "all_properties['total_room_count'] = all_properties[['bedrooms', 'bathrooms', 'livingRooms']].sum(axis=1)\n",
    "all_properties['house_type'] = all_properties['tenure'] + '-' + all_properties['propertyType']\n",
    "\n",
    "categorical_columns = ['bed-bath', 'bed-liv', 'bed-bath-liv', 'postcode', 'outcode', 'bathrooms', 'bedrooms', 'livingRooms', 'tenure', 'propertyType', 'currentEnergyRating', 'saleEstimate_confidenceLevel', 'quadrant', 'Area_Binned_Low_500','Area_Binned_Low_250', 'Area_Binned_Low_10', 'total_room_count', 'house_type']\n",
    "needed_columns = categorical_columns + ['floorAreaSqM', 'latitude', 'longitude', 'history_price', 'month', 'quarter', 'year', 'week', 'dayofmonth', 'dayofyear']\n",
    "df = all_properties.sort_values(by=['history_date'])[needed_columns]\n",
    "outcode_count = df.groupby(by=['outcode']).size().sort_values().reset_index()\n",
    "df = df[df['outcode'].isin(outcode_count[outcode_count[0]>400]['outcode'].tolist())]\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df['average_sq_per_room'] = (df['floorAreaSqM'] / df['total_room_count']).replace({np.inf:np.nan})\n",
    "df['average_sq_per_bed_livingrooms'] = (df['floorAreaSqM'] / df[['bedrooms', 'livingRooms']].sum(axis=1)).replace({np.inf:np.nan})\n",
    "df['average_sq_per_bed_bathrooms'] = (df['floorAreaSqM'] / df[['bedrooms', 'bathrooms']].sum(axis=1)).replace({np.inf:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df = df.dropna(subset=['history_price'])\n",
    "df['history_log_price'] = np.log(df['history_price'])\n",
    "test_size=0.05\n",
    "\n",
    "test_size = int(df.shape[0]*test_size)\n",
    "final_test_size = int(test_size*0.3)\n",
    "\n",
    "train_set = df.head(-test_size)\n",
    "test_set = df.tail(test_size)\n",
    "\n",
    "\n",
    "for col in ['outcode']:\n",
    "    total_mean_outcode_average = train_set.groupby(by=col)['history_price'].mean().reset_index().rename(columns={'history_price':f'total_average_{col}_price'})\n",
    "    total_median_outcode_average = train_set.groupby(by=col)['history_price'].median().reset_index().rename(columns={'history_price':f'total_median_{col}_price'})\n",
    "    total_mean_outcode_average_log = train_set.groupby(by=col)['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'total_average_{col}_log_price'})\n",
    "    total_median_outcode_average_log = train_set.groupby(by=col)['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'total_median_{col}_log_price'})\n",
    "    \n",
    "    train_set = train_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    test_set = test_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    for period in ['month', 'year', 'week', 'dayofmonth', 'dayofyear']:\n",
    "        mean_outcode_average = train_set.groupby(by=[col, period])['history_price'].mean().reset_index().rename(columns={'history_price':f'average_{col}_price_wrt_{period}'})\n",
    "        median_outcode_average = train_set.groupby(by=[col, period])['history_price'].median().reset_index().rename(columns={'history_price':f'median_{col}_price_wrt_{period}'})\n",
    "        mean_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'average_{col}_log_price_wrt_{period}'})\n",
    "        median_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'median_{col}_log_price_wrt_{period}'})\n",
    "\n",
    "\n",
    "        train_set = train_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "        test_set = test_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "train_set = train_set.dropna(subset=['history_price'])\n",
    "test_set = test_set.dropna(subset=['history_price'])\n",
    "\n",
    "final_test_set = test_set.tail(final_test_size)\n",
    "test_set = test_set.head(-final_test_size)\n",
    "\n",
    "X_train, y_train = train_set.drop(columns=['history_price', 'history_log_price']),  train_set['history_price']\n",
    "X_test, y_test = test_set.drop(columns=['history_price', 'history_log_price']),  test_set['history_price']\n",
    "\n",
    "X_test_final, y_test_final = final_test_set.drop(columns=['history_price', 'history_log_price']), final_test_set['history_price']\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-2, subsample=0.8, colsample_bytree=0.8, linear_tree=False)\n",
    "xgb_model = xgb.XGBRegressor(enable_categorical=True, colsample_bytree=0.8)\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "week_columns = [col for col in X_train.columns if 'week' in col]\n",
    "dayofmonth_columns = [col for col in X_train.columns if 'dayofmonth' in col]\n",
    "dayofyear_columns = [col for col in X_train.columns if 'dayofyear' in col]\n",
    "\n",
    "month_columns = [col for col in X_train.columns if 'month' in col and 'dayofmonth' not in col]\n",
    "year_columns = [col for col in X_train.columns if 'year' in col and 'dayofyear' not in col]\n",
    "\n",
    "sq_ft_columns = ['average_sq_per_room', 'average_sq_per_bed_livingrooms', 'average_sq_per_bed_bathrooms']\n",
    "bed_bathroom_columns = ['bed-bath-liv', 'bed-liv', 'bed-bath']\n",
    "binned_columns = ['Area_Binned_Low_500', 'Area_Binned_Low_250', 'Area_Binned_Low_10']\n",
    "mean_absolute_error(y_pred=lgb_model.predict(X_test), y_true=y_test)\n",
    "181832.34616247966\n",
    "mean_absolute_error(y_pred=xgb_model.predict(X_test), y_true=y_test)\n",
    "186726.1618394154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['outcode']:\n",
    "    total_mean_outcode_average = train_set.groupby(by=col)['history_price'].mean().reset_index().rename(columns={'history_price':f'total_average_{col}_price'})\n",
    "    total_median_outcode_average = train_set.groupby(by=col)['history_price'].median().reset_index().rename(columns={'history_price':f'total_median_{col}_price'})\n",
    "    total_mean_outcode_average_log = train_set.groupby(by=col)['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'total_average_{col}_log_price'})\n",
    "    total_median_outcode_average_log = train_set.groupby(by=col)['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'total_median_{col}_log_price'})\n",
    "    \n",
    "    train_set = train_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    test_set = test_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    for period in ['month', 'year', 'week', 'dayofmonth', 'dayofyear']:\n",
    "        mean_outcode_average = train_set.groupby(by=[col, period])['history_price'].mean().reset_index().rename(columns={'history_price':f'average_{col}_price_wrt_{period}'})\n",
    "        median_outcode_average = train_set.groupby(by=[col, period])['history_price'].median().reset_index().rename(columns={'history_price':f'median_{col}_price_wrt_{period}'})\n",
    "        mean_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'average_{col}_log_price_wrt_{period}'})\n",
    "        median_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'median_{col}_log_price_wrt_{period}'})\n",
    "\n",
    "\n",
    "        train_set = train_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "        test_set = test_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "train_set = train_set.dropna(subset=['history_price'])\n",
    "test_set = test_set.dropna(subset=['history_price'])\n",
    "\n",
    "final_test_set = test_set.tail(final_test_size)\n",
    "test_set = test_set.head(-final_test_size)\n",
    "\n",
    "X_train, y_train = train_set.drop(columns=['history_price', 'history_log_price']),  train_set['history_price']\n",
    "X_test, y_test = test_set.drop(columns=['history_price', 'history_log_price']),  test_set['history_price']\n",
    "\n",
    "X_test_final, y_test_final = final_test_set.drop(columns=['history_price', 'history_log_price']), final_test_set['history_price']\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-2, subsample=0.8, colsample_bytree=0.8, linear_tree=False)\n",
    "xgb_model = xgb.XGBRegressor(enable_categorical=True, colsample_bytree=0.8)\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "week_columns = [col for col in X_train.columns if 'week' in col]\n",
    "dayofmonth_columns = [col for col in X_train.columns if 'dayofmonth' in col]\n",
    "dayofyear_columns = [col for col in X_train.columns if 'dayofyear' in col]\n",
    "\n",
    "month_columns = [col for col in X_train.columns if 'month' in col and 'dayofmonth' not in col]\n",
    "year_columns = [col for col in X_train.columns if 'year' in col and 'dayofyear' not in col]\n",
    "\n",
    "sq_ft_columns = ['average_sq_per_room', 'average_sq_per_bed_livingrooms', 'average_sq_per_bed_bathrooms']\n",
    "bed_bathroom_columns = ['bed-bath-liv', 'bed-liv', 'bed-bath']\n",
    "binned_columns = ['Area_Binned_Low_500', 'Area_Binned_Low_250', 'Area_Binned_Low_10']\n",
    "mean_absolute_error(y_pred=lgb_model.predict(X_test), y_true=y_test)\n",
    "181832.34616247966\n",
    "mean_absolute_error(y_pred=xgb_model.predict(X_test), y_true=y_test)\n",
    "186726.1618394154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_properties = pd.read_parquet('/kaggle/input/house-price-data/kaggle_london_house_price_data.parquet').reset_index(drop=True)\n",
    "all_properties['history_date'] = pd.to_datetime(all_properties['history_date'])\n",
    "\n",
    "all_properties['week'] = all_properties['history_date'].dt.isocalendar().week\n",
    "all_properties['dayofyear'] = all_properties['history_date'].dt.day_of_year\n",
    "all_properties['dayofmonth'] = all_properties['history_date'].dt.day\n",
    "\n",
    "all_properties['month'] = all_properties['history_date'].dt.month\n",
    "all_properties['year'] = all_properties['history_date'].dt.year\n",
    "all_properties['quarter'] = all_properties['history_date'].dt.quarter\n",
    "\n",
    "all_properties['bed-bath'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['bathrooms'].astype(str)\n",
    "all_properties['bed-liv'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['livingRooms'].astype(str)\n",
    "all_properties['bed-bath-liv'] = all_properties['bedrooms'].astype(str) +'-'+ all_properties['bathrooms'].astype(str) +'-'+ all_properties['livingRooms'].astype(str)\n",
    "\n",
    "all_properties['Area_Binned_Low_500'] = pd.cut(all_properties['floorAreaSqM'], bins=500).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "all_properties['Area_Binned_Low_250'] = pd.cut(all_properties['floorAreaSqM'], bins=250).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "all_properties['Area_Binned_Low_10'] = pd.cut(all_properties['floorAreaSqM'], bins=10).apply(lambda x: x.left if pd.notnull(x) else None)\n",
    "\n",
    "all_properties['quadrant'] = all_properties['postcode'].str[:1]\n",
    "all_properties['total_room_count'] = all_properties[['bedrooms', 'bathrooms', 'livingRooms']].sum(axis=1)\n",
    "all_properties['house_type'] = all_properties['tenure'] + '-' + all_properties['propertyType']\n",
    "\n",
    "categorical_columns = ['bed-bath', 'bed-liv', 'bed-bath-liv', 'postcode', 'outcode', 'bathrooms', 'bedrooms', 'livingRooms', 'tenure', 'propertyType', 'currentEnergyRating', 'saleEstimate_confidenceLevel', 'quadrant', 'Area_Binned_Low_500','Area_Binned_Low_250', 'Area_Binned_Low_10', 'total_room_count', 'house_type']\n",
    "needed_columns = categorical_columns + ['floorAreaSqM', 'latitude', 'longitude', 'history_price', 'month', 'quarter', 'year', 'week', 'dayofmonth', 'dayofyear']\n",
    "df = all_properties.sort_values(by=['history_date'])[needed_columns]\n",
    "outcode_count = df.groupby(by=['outcode']).size().sort_values().reset_index()\n",
    "df = df[df['outcode'].isin(outcode_count[outcode_count[0]>400]['outcode'].tolist())]\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df['average_sq_per_room'] = (df['floorAreaSqM'] / df['total_room_count']).replace({np.inf:np.nan})\n",
    "df['average_sq_per_bed_livingrooms'] = (df['floorAreaSqM'] / df[['bedrooms', 'livingRooms']].sum(axis=1)).replace({np.inf:np.nan})\n",
    "df['average_sq_per_bed_bathrooms'] = (df['floorAreaSqM'] / df[['bedrooms', 'bathrooms']].sum(axis=1)).replace({np.inf:np.nan})\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df = df.dropna(subset=['history_price'])\n",
    "df['history_log_price'] = np.log(df['history_price'])\n",
    "test_size=0.05\n",
    "\n",
    "test_size = int(df.shape[0]*test_size)\n",
    "final_test_size = int(test_size*0.3)\n",
    "\n",
    "train_set = df.head(-test_size)\n",
    "test_set = df.tail(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['outcode']:\n",
    "    total_mean_outcode_average = train_set.groupby(by=col)['history_price'].mean().reset_index().rename(columns={'history_price':f'total_average_{col}_price'})\n",
    "    total_median_outcode_average = train_set.groupby(by=col)['history_price'].median().reset_index().rename(columns={'history_price':f'total_median_{col}_price'})\n",
    "    total_mean_outcode_average_log = train_set.groupby(by=col)['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'total_average_{col}_log_price'})\n",
    "    total_median_outcode_average_log = train_set.groupby(by=col)['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'total_median_{col}_log_price'})\n",
    "    \n",
    "    train_set = train_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    train_set = train_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    test_set = test_set.merge(total_mean_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_mean_outcode_average_log, how='outer', on=col)\n",
    "    test_set = test_set.merge(total_median_outcode_average_log, how='outer', on=col)\n",
    "    \n",
    "    for period in ['month', 'year', 'week', 'dayofmonth', 'dayofyear']:\n",
    "        mean_outcode_average = train_set.groupby(by=[col, period])['history_price'].mean().reset_index().rename(columns={'history_price':f'average_{col}_price_wrt_{period}'})\n",
    "        median_outcode_average = train_set.groupby(by=[col, period])['history_price'].median().reset_index().rename(columns={'history_price':f'median_{col}_price_wrt_{period}'})\n",
    "        mean_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].mean().reset_index().rename(columns={'history_log_price':f'average_{col}_log_price_wrt_{period}'})\n",
    "        median_outcode_average_log = train_set.groupby(by=[col, period])['history_log_price'].median().reset_index().rename(columns={'history_log_price':f'median_{col}_log_price_wrt_{period}'})\n",
    "\n",
    "\n",
    "        train_set = train_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        train_set = train_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "        test_set = test_set.merge(mean_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(mean_outcode_average_log, how='outer', on=[col, period])\n",
    "        test_set = test_set.merge(median_outcode_average_log, how='outer', on=[col, period])\n",
    "\n",
    "train_set = train_set.dropna(subset=['history_price'])\n",
    "test_set = test_set.dropna(subset=['history_price'])\n",
    "\n",
    "final_test_set = test_set.tail(final_test_size)\n",
    "test_set = test_set.head(-final_test_size)\n",
    "\n",
    "X_train, y_train = train_set.drop(columns=['history_price', 'history_log_price']),  train_set['history_price']\n",
    "X_test, y_test = test_set.drop(columns=['history_price', 'history_log_price']),  test_set['history_price']\n",
    "\n",
    "X_test_final, y_test_final = final_test_set.drop(columns=['history_price', 'history_log_price']), final_test_set['history_price']\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-2, subsample=0.8, colsample_bytree=0.8, linear_tree=False)\n",
    "xgb_model = xgb.XGBRegressor(enable_categorical=True, colsample_bytree=0.8)\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "week_columns = [col for col in X_train.columns if 'week' in col]\n",
    "dayofmonth_columns = [col for col in X_train.columns if 'dayofmonth' in col]\n",
    "dayofyear_columns = [col for col in X_train.columns if 'dayofyear' in col]\n",
    "\n",
    "month_columns = [col for col in X_train.columns if 'month' in col and 'dayofmonth' not in col]\n",
    "year_columns = [col for col in X_train.columns if 'year' in col and 'dayofyear' not in col]\n",
    "\n",
    "sq_ft_columns = ['average_sq_per_room', 'average_sq_per_bed_livingrooms', 'average_sq_per_bed_bathrooms']\n",
    "bed_bathroom_columns = ['bed-bath-liv', 'bed-liv', 'bed-bath']\n",
    "binned_columns = ['Area_Binned_Low_500', 'Area_Binned_Low_250', 'Area_Binned_Low_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_pred=lgb_model.predict(X_test), y_true=y_test)\n",
    "# 181832.34616247966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_pred=xgb_model.predict(X_test), y_true=y_test)\n",
    "# 186726.1618394154"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
