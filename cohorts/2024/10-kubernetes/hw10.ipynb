{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Run it to test that it's working locally:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 9696:9696 svizor/zoomcamp-model:3.11.5-hw10\n",
    "```\n",
    "\n",
    "And in another terminal, execute `q6_test.py` file:\n",
    "\n",
    "```bash\n",
    "python q6_test.py\n",
    "```\n",
    "\n",
    "You should see this:\n",
    "\n",
    "```python\n",
    "{'has_subscribed': True, 'has_subscribed_probability': <value>}\n",
    "```\n",
    "\n",
    "Here `<value>` is the probability of getting a subscription. You need to choose the right one.\n",
    "\n",
    "* 0.287\n",
    "* 0.530\n",
    "* 0.757   `<--`\n",
    "* 0.960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `kind` to create a local Kubernetes cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubectl controls the Kubernetes cluster manager.\n",
      "\n",
      " Find more information at: https://kubernetes.io/docs/reference/kubectl/\n",
      "\n",
      "Basic Commands (Beginner):\n",
      "  create          Create a resource from a file or from stdin\n",
      "  expose          Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service\n",
      "  run             Run a particular image on the cluster\n",
      "  set             Set specific features on objects\n",
      "\n",
      "Basic Commands (Intermediate):\n",
      "  explain         Get documentation for a resource\n",
      "  get             Display one or many resources\n",
      "  edit            Edit a resource on the server\n",
      "  delete          Delete resources by file names, stdin, resources and names, or by resources and label selector\n",
      "\n",
      "Deploy Commands:\n",
      "  rollout         Manage the rollout of a resource\n",
      "  scale           Set a new size for a deployment, replica set, or replication controller\n",
      "  autoscale       Auto-scale a deployment, replica set, stateful set, or replication controller\n",
      "\n",
      "Cluster Management Commands:\n",
      "  certificate     Modify certificate resources\n",
      "  cluster-info    Display cluster information\n",
      "  top             Display resource (CPU/memory) usage\n",
      "  cordon          Mark node as unschedulable\n",
      "  uncordon        Mark node as schedulable\n",
      "  drain           Drain node in preparation for maintenance\n",
      "  taint           Update the taints on one or more nodes\n",
      "\n",
      "Troubleshooting and Debugging Commands:\n",
      "  describe        Show details of a specific resource or group of resources\n",
      "  logs            Print the logs for a container in a pod\n",
      "  attach          Attach to a running container\n",
      "  exec            Execute a command in a container\n",
      "  port-forward    Forward one or more local ports to a pod\n",
      "  proxy           Run a proxy to the Kubernetes API server\n",
      "  cp              Copy files and directories to and from containers\n",
      "  auth            Inspect authorization\n",
      "  debug           Create debugging sessions for troubleshooting workloads and nodes\n",
      "  events          List events\n",
      "\n",
      "Advanced Commands:\n",
      "  diff            Diff the live version against a would-be applied version\n",
      "  apply           Apply a configuration to a resource by file name or stdin\n",
      "  patch           Update fields of a resource\n",
      "  replace         Replace a resource by file name or stdin\n",
      "  wait            Experimental: Wait for a specific condition on one or many resources\n",
      "  kustomize       Build a kustomization target from a directory or URL\n",
      "\n",
      "Settings Commands:\n",
      "  label           Update the labels on a resource\n",
      "  annotate        Update the annotations on a resource\n",
      "  completion      Output shell completion code for the specified shell (bash, zsh, fish, or powershell)\n",
      "\n",
      "Subcommands provided by plugins:\n",
      "\n",
      "Other Commands:\n",
      "  api-resources   Print the supported API resources on the server\n",
      "  api-versions    Print the supported API versions on the server, in the form of \"group/version\"\n",
      "  config          Modify kubeconfig files\n",
      "  plugin          Provides utilities for interacting with plugins\n",
      "  version         Print the client and server version information\n",
      "\n",
      "Usage:\n",
      "  kubectl [flags] [options]\n",
      "\n",
      "Use \"kubectl <command> --help\" for more information about a given command.\n",
      "Use \"kubectl options\" for a list of global command-line options (applies to all commands).\n"
     ]
    }
   ],
   "source": [
    "!kubectl --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the version of `kind` that you have? \n",
    "\n",
    "Use `kind --version` to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind version 0.25.0\n"
     ]
    }
   ],
   "source": [
    "!kind --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating cluster \"hw09\" ...\n",
      " ‚Ä¢ Ensuring node image (kindest/node:v1.31.2) üñº  ...\n",
      " ‚úì Ensuring node image (kindest/node:v1.31.2) üñº\n",
      " ‚Ä¢ Preparing nodes üì¶   ...\n",
      " ‚úì Preparing nodes üì¶ \n",
      " ‚Ä¢ Writing configuration üìú  ...\n",
      " ‚úì Writing configuration üìú\n",
      " ‚Ä¢ Starting control-plane üïπÔ∏è  ...\n",
      " ‚úì Starting control-plane üïπÔ∏è\n",
      " ‚Ä¢ Installing CNI üîå  ...\n",
      " ‚úì Installing CNI üîå\n",
      " ‚Ä¢ Installing StorageClass üíæ  ...\n",
      " ‚úì Installing StorageClass üíæ\n",
      "Set kubectl context to \"kind-hw09\"\n",
      "You can now use your cluster with:\n",
      "\n",
      "kubectl cluster-info --context kind-hw09\n",
      "\n",
      "Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community üôÇ\n"
     ]
    }
   ],
   "source": [
    "!kind create cluster --name hw09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes control plane is running at https://127.0.0.1:58171\n",
      "CoreDNS is running at https://127.0.0.1:58171/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
     ]
    }
   ],
   "source": [
    "!kubectl cluster-info --context kind-hw09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What's the smallest deployable computing unit that we can create and manage \n",
    "in Kubernetes (`kind` in our case)?\n",
    "\n",
    "* Node\n",
    "* Pod  `<--`\n",
    "* Deployment\n",
    "* Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's test if everything works. Use `kubectl` to get the list of running services.\n",
    "\n",
    "What's the `Type` of the service that is already running there?\n",
    "\n",
    "* NodePort\n",
    "* ClusterIP   `<--`\n",
    "* ExternalName\n",
    "* LoadBalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   77m\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No resources found in default namespace.\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No resources found in default namespace.\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py): started\n",
      "  Building wheel for GPUtil (setup.py): finished with status 'done'\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7399 sha256=d59a796e4ac235e84aad50e368b5f557079e0e0cb8116afabca9cbc4037c7e62\n",
      "  Stored in directory: c:\\users\\julrich\\appdata\\local\\pip\\cache\\wheels\\2b\\4d\\8f\\55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GPUtil\n",
    "\n",
    "GPUtil.getAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "To be able to use the docker image we previously created (`zoomcamp-model:3.11.5-hw10`),\n",
    "we need to register it with `kind`.\n",
    "\n",
    "What's the command we need to run for that?\n",
    "\n",
    "* `kind create cluster`\n",
    "* `kind build node-image`\n",
    "* `kind load docker-image`   `<--`\n",
    "* `kubectl apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image: \"svizor/zoomcamp-model:3.11.5-hw10\" with ID \"sha256:020904a2523cec81c854a9b4679ae26d23f814e42350721136d1447f910a6b53\" not yet present on node \"hw09-control-plane\", loading...\n"
     ]
    }
   ],
   "source": [
    "!kind load docker-image --name hw09 svizor/zoomcamp-model:3.11.5-hw10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's create a deployment config (e.g. `deployment.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: subscription\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: subscription\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: subscription\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: subscription\n",
    "        image: <Image>\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64Mi\"\n",
    "            cpu: \"100m\"            \n",
    "          limits:\n",
    "            memory: <Memory>\n",
    "            cpu: <CPU>\n",
    "        ports:\n",
    "        - containerPort: <Port>\n",
    "```\n",
    "\n",
    "Replace `<Image>`, `<Memory>`, `<CPU>`, `<Port>` with the correct values.\n",
    "\n",
    "What is the value for `<Port>`?   `9696`\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows 10 Pro\n",
      " Volume Serial Number is 6A14-E860\n",
      "\n",
      " Directory of c:\\Projects\\learning\\datatalksclub\\machine-learning-zoomcamp\\cohorts\\2024\\10-kubernetes\n",
      "\n",
      "13/12/2024  13:56    <DIR>          .\n",
      "13/12/2024  13:56    <DIR>          ..\n",
      "13/12/2024  13:56             6,453 homework.md\n",
      "13/12/2024  15:56            11,626 hw10.ipynb\n",
      "13/12/2024  14:27    <DIR>          kubernetes\n",
      "               2 File(s)         18,079 bytes\n",
      "               3 Dir(s)  40,377,585,664 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/subscription created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f kubernetes/deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "subscription   1/1     1            1           60s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                           READY   STATUS    RESTARTS   AGE\n",
      "subscription-dd89dfd5f-qgf86   1/1     Running   0          86s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             subscription-dd89dfd5f-qgf86\n",
      "Namespace:        default\n",
      "Priority:         0\n",
      "Service Account:  default\n",
      "Node:             hw09-control-plane/172.18.0.2\n",
      "Start Time:       Fri, 13 Dec 2024 16:08:05 +0000\n",
      "Labels:           app=subscription\n",
      "                  pod-template-hash=dd89dfd5f\n",
      "Annotations:      <none>\n",
      "Status:           Running\n",
      "IP:               10.244.0.5\n",
      "IPs:\n",
      "  IP:           10.244.0.5\n",
      "Controlled By:  ReplicaSet/subscription-dd89dfd5f\n",
      "Containers:\n",
      "  subscription:\n",
      "    Container ID:   containerd://e1d13b956bf2714ae37db6af3bbb78959a2a9c51c1919f7eb0948a5e1b544831\n",
      "    Image:          svizor/zoomcamp-model:3.11.5-hw10\n",
      "    Image ID:       docker.io/library/import-2024-12-13@sha256:ed075d03a306c99aa765898c1bb76e7013cd6f46ed963e6c2bb219f648ed58c4\n",
      "    Port:           9696/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Running\n",
      "      Started:      Fri, 13 Dec 2024 16:08:06 +0000\n",
      "    Ready:          True\n",
      "    Restart Count:  0\n",
      "    Limits:\n",
      "      cpu:     500m\n",
      "      memory:  500Mi\n",
      "    Requests:\n",
      "      cpu:        100m\n",
      "      memory:     64Mi\n",
      "    Environment:  <none>\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-fxspf (ro)\n",
      "Conditions:\n",
      "  Type                        Status\n",
      "  PodReadyToStartContainers   True \n",
      "  Initialized                 True \n",
      "  Ready                       True \n",
      "  ContainersReady             True \n",
      "  PodScheduled                True \n",
      "Volumes:\n",
      "  kube-api-access-fxspf:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Burstable\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type    Reason     Age   From               Message\n",
      "  ----    ------     ----  ----               -------\n",
      "  Normal  Scheduled  2m3s  default-scheduler  Successfully assigned default/subscription-dd89dfd5f-qgf86 to hw09-control-plane\n",
      "  Normal  Pulled     2m2s  kubelet            Container image \"svizor/zoomcamp-model:3.11.5-hw10\" already present on machine\n",
      "  Normal  Created    2m2s  kubelet            Created container subscription\n",
      "  Normal  Started    2m2s  kubelet            Started container subscription\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pod subscription-dd89dfd5f-qgf86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Let's create a service for this deployment (`service.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: <Service name>\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: <???>\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: <PORT>\n",
    "```\n",
    "\n",
    "Fill it in. What do we need to write instead of `<???>`?   `subscription`\n",
    "\n",
    "Apply this config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/lb-subscription created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f .\\kubernetes\\service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\n",
      "kubernetes        ClusterIP      10.96.0.1      <none>        443/TCP        126m\n",
      "lb-subscription   LoadBalancer   10.96.202.56   <pending>     80:31647/TCP   27s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the service\n",
    "\n",
    "We can test our service locally by forwarding the port 9696 on our computer \n",
    "to the port 80 on the service:\n",
    "\n",
    "```bash\n",
    "kubectl port-forward service/<Service name> 9696:80\n",
    "```\n",
    "\n",
    "Run `q6_test.py` (from the homework 5) once again to verify that everything is working. \n",
    "You should get the same result as in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl port-forward service/lb-subscription 9696:80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoscaling\n",
    "\n",
    "Now we're going to use a [HorizontalPodAutoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/) \n",
    "(HPA for short) that automatically updates a workload resource (such as our deployment), \n",
    "with the aim of automatically scaling the workload to match demand.\n",
    "\n",
    "Use the following command to create the HPA:\n",
    "\n",
    "```bash\n",
    "kubectl autoscale deployment subscription --name subscription-hpa --cpu-percent=20 --min=1 --max=3\n",
    "```\n",
    "\n",
    "You can check the current status of the new HPA by running:\n",
    "\n",
    "```bash\n",
    "kubectl get hpa\n",
    "```\n",
    "\n",
    "The output should be similar to the next:\n",
    "\n",
    "```bash\n",
    "NAME               REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
    "subscription-hpa   Deployment/subscription   1%/20%    1         3         1          27s\n",
    "```\n",
    "\n",
    "`TARGET` column shows the average CPU consumption across all the Pods controlled by the corresponding deployment.\n",
    "Current CPU consumption is about 0% as there are no clients sending requests to the server.\n",
    "> \n",
    ">Note: In case the HPA instance doesn't run properly, try to install the latest Metrics Server release \n",
    "> from the `components.yaml` manifest:\n",
    "> ```bash\n",
    "> kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontalpodautoscaler.autoscaling/subscription-hpa autoscaled\n"
     ]
    }
   ],
   "source": [
    "!kubectl autoscale deployment subscription --name subscription-hpa --cpu-percent=20 --min=1 --max=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               REFERENCE                 TARGETS              MINPODS   MAXPODS   REPLICAS   AGE\n",
      "subscription-hpa   Deployment/subscription   cpu: <unknown>/20%   1         3         1          6m8s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the load\n",
    "\n",
    "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing\n",
    "`q6_test.py` script by putting the operator that sends the request to the subscription service into a loop.\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    sleep(0.1)\n",
    "    response = requests.post(url, json=client).json()\n",
    "    print(response)\n",
    "```\n",
    "\n",
    "Now you can run this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (optional)\n",
    "\n",
    "Run `kubectl get hpa subscription-hpa --watch` command to monitor how the autoscaler performs. \n",
    "Within a minute or so, you should see the higher CPU load; and then - more replicas. \n",
    "What was the maximum amount of the replicas during this test?\n",
    "\n",
    "\n",
    "* 1    `<--`\n",
    "* 2\n",
    "* 3\n",
    "* 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "09-serverless-9sYwZBkw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
